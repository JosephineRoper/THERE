{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec4193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandana as pdna\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import math\n",
    "import networkx as nx\n",
    "import sys\n",
    "# adding functions \n",
    "sys.path.insert(0, 'C:\\\\Users\\\\z3258367\\\\OneDrive - UNSW\\\\#PhD\\\\Walkability\\\\Other Cities\\\\Open-Walk-Index')\n",
    "from walkability_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40338e69",
   "metadata": {},
   "source": [
    "Choose a projected CRS to be used for all distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e28571a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_crs = \"EPSG:7855\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865078a9",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "Data sources:\n",
    "1. Shape of Greater Melbourne - used to clip points if not already clipped to the city\n",
    "2. Points of interest from OSM\n",
    "3. PTV public transport stops\n",
    "4. Additional POIs from VicMaps Features of Interest collection\n",
    "5. Employment data - processed from ABS originally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a6398e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:\\\\Users\\\\z3258367\\\\OneDrive - UNSW\\\\#PhD\\\\Walkability\\\\Other Cities\\\\Melbourne Data\\\\\"\n",
    "data = \"C:\\\\Users\\\\z3258367\\\\OneDrive - UNSW\\\\#PhD\\\\Data\\\\\"\n",
    "Greater_Melbourne = gpd.read_file((folder + \n",
    "                                   \"Greater_Melbourne_GCCSA_2016.shp\")\n",
    "                                 ).to_crs(proj_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c494196",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_poi_points = gpd.read_file(''.join((data, \n",
    "    \"OSM-australia-latest-free\\\\gis_osm_pois_free_1.shp\")))\n",
    "osm_poi_areas = gpd.read_file(data + \n",
    "    \"OSM-australia-latest-free\\\\gis_osm_pois_a_free_1.shp\")\n",
    "osm_transport_points = gpd.read_file(data +\n",
    "    \"OSM-australia-latest-free\\\\gis_osm_transport_free_1.shp\")\n",
    "osm_transport_areas =  gpd.read_file(data +\n",
    "    \"OSM-australia-latest-free\\\\gis_osm_transport_a_free_1.shp\")\n",
    "osm_parks_vertices = gpd.read_file(''.join((data, \n",
    "    \"OSM-australia-latest-free\\\\OSM parks vertices.gpkg\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d48e4c3",
   "metadata": {},
   "source": [
    "Convert polygonal datasets to points and any multipart datasets to single part. Clip OSM data to Greater Melbourne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ebdc1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_pois_2 = single_points(osm_poi_areas)\n",
    "osm_transport_2 = single_points(osm_transport_areas)\n",
    "osm_parks_vertices = single_points(osm_parks_vertices)\n",
    "\n",
    "osm_df = pd.concat([osm_poi_points, osm_pois_2, osm_transport_points, \n",
    "                    osm_transport_2, osm_parks_vertices]).to_crs(proj_crs)\n",
    "\n",
    "osm_df = gpd.clip(osm_df, Greater_Melbourne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1b076",
   "metadata": {},
   "source": [
    "Import PTV data - already clipped to Greater Melbourne area, VicMaps data, and employment data (prepared using Employment points.ipnyb and ABS data).\n",
    "I have added specific service type columns at this point, even though they will be rolled into 'train' and 'other' for now, to make it easier to change the categories later if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49a68580",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = gpd.read_file(folder + \"PTV data\\\\PTV_METRO_BUS_STOP.SHP\").assign(fclass='bus')\n",
    "regional_bus = gpd.read_file(folder + \"PTV data\\\\PTV_REGIONAL_BUS_STOP.SHP\").assign(fclass='regional_bus')\n",
    "tram = gpd.read_file(folder + \"PTV data\\\\PTV_METRO_TRAM_STOP.SHP\").assign(fclass='tram')\n",
    "coach = gpd.read_file(folder + \"PTV data\\\\PTV_REGIONAL_COACH_STOP.SHP\").assign(fclass='coach')\n",
    "train = gpd.read_file(folder + \"PTV data\\\\PTV_REGIONAL_TRAIN_STATION.SHP\").assign(fclass='regional_train')\n",
    "regional_train = gpd.read_file(folder + \"PTV data\\\\PTV_METRO_TRAIN_STATION.SHP\").assign(fclass='train')\n",
    "\n",
    "PTV = pd.concat([bus, regional_bus, tram, coach, train, regional_train]).to_crs(proj_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25120e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vicmaps_points = gpd.read_file(folder + \"VicMap Features of Interest\\\\FOI_POINT.shp\")\n",
    "vicmaps_areas = gpd.read_file(folder + \"VicMap Features of Interest\\\\VMFOI.gdb\")\n",
    "\n",
    "vicmaps = pd.concat([vicmaps_points, vicmaps_areas]).to_crs(proj_crs)\n",
    "\n",
    "vicmaps = gpd.clip(vicmaps, Greater_Melbourne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d8bb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_centrs = gpd.read_file(folder + \"Vic_Employment_meshblocks.gpkg\").to_crs(proj_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31928c3",
   "metadata": {},
   "source": [
    "### Categorise and weight POIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b70870",
   "metadata": {},
   "source": [
    "Categorise POI data - change classes depending on your analysis and your data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "588f14e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags present in the dataset but not categorised:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "metro_categories = {'transport':['bus', 'regional_bus', 'tram'], \n",
    "                    'trains':['train', 'regional_train', 'coach']}\n",
    "\n",
    "metro_categorised = categorise_pois(PTV, metro_categories, \n",
    "                                 category_column='fclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "19d17999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags present in the dataset but not categorised:\n",
      "['toilet' 'bench' 'drinking_water' 'shelter' 'camp_site' 'monument'\n",
      " 'memorial' 'fire_station' 'telephone' 'tourist_info' 'hunting_stand'\n",
      " 'camera_surveillance' 'waste_basket' 'motel' 'caravan_site' 'graveyard'\n",
      " 'fountain' 'guesthouse' 'water_tower' 'tower' 'police' 'public_building'\n",
      " 'vending_any' 'hotel' 'nursing_home' 'comms_tower' 'vending_parking'\n",
      " 'recycling' 'lighthouse' 'wastewater_plant' 'bicycle_rental'\n",
      " 'bed_and_breakfast' 'courthouse' 'town_hall' 'car_rental'\n",
      " 'vending_machine' 'taxi' 'hostel' 'water_well' 'water_works'\n",
      " 'recycling_clothes' 'recycling_glass' 'chalet' 'prison' 'embassy'\n",
      " 'recycling_paper' 'alpine_hut']\n"
     ]
    }
   ],
   "source": [
    "osm_categories = {\"eating\" : ['restaurant', 'pub', 'cafe', 'fast_food', \n",
    "                              'food_court', 'bakery', 'bar', 'nightclub', 'biergarten'], \n",
    "                  'groceries' : ['supermarket', 'chemist', 'pharmacy', 'greengrocer', \n",
    "                                 'convenience', 'butcher', 'beverages', 'alcohol'], \n",
    "                  'shopping' : ['mall', 'bicycle_shop', 'clothes', \n",
    "                                'department_store', 'doityourself', \n",
    "                                'outdoor_shop', 'stationery', 'bookshop', \n",
    "                                'gift_shop', 'newsagent', 'car_dealership', \n",
    "                                'kiosk', 'furniture_shop', 'sports_shop', \n",
    "                                'garden_centre', 'computer_shop', 'shoe_shop', \n",
    "                                'beauty_shop', 'florist', 'video_shop', 'toy_shop', \n",
    "                                'mobile_phone_shop', 'jeweller', 'travel_agent'], \n",
    "                  'errands' : ['post_box', 'post_office', 'bank', 'atm',\n",
    "                               'doctors', 'dentist', 'laundry', 'hospital',\n",
    "                               'car_wash', 'veterinary', 'hairdresser', 'optician'], \n",
    "                  'parks' : ['viewpoint', 'park', 'playground', 'picnic_site', \n",
    "                             'pitch', 'swimming_pool', 'sports_centre', \n",
    "                             'golf_course', 'track', 'dog_park'], \n",
    "                  'education' : ['college', 'school', 'kindergarten', 'university'], \n",
    "                  'entertainment' : ['library', 'attraction', 'stadium', \n",
    "                                     'arts_centre', 'theatre', 'artwork', \n",
    "                                     'archaeological', 'cinema', 'museum', \n",
    "                                     'ruins', 'observation_tower', \n",
    "                                     'community_centre', 'zoo', 'castle', \n",
    "                                     'theme_park', 'ice_rink'], \n",
    "                 'trains' : ['ferry_terminal', 'railway_station', 'bus_station', \n",
    "                             'tram_stop', 'railway_halt', 'publictransport'], \n",
    "                 'transport' : ['car_sharing', 'bus_stop']}\n",
    "\n",
    "osm_categorised = categorise_pois(osm_df, osm_categories, \n",
    "                                  category_column='fclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040452bb",
   "metadata": {},
   "source": [
    "In the VicMaps data, the 'community space' collection is caravan parks, camping areas (generally outside Greater Melbourne) and rest areas, not considered relevant. The 'community venue' collection is community centres, halls, senior clubs, scouts etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b9a148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags present in the dataset but not categorised:\n",
      "['sign' 'landmark' 'care facility' 'emergency facility'\n",
      " 'communication service' nan 'community space' 'admin facility'\n",
      " 'dumping ground' 'control point' 'excavation site' 'place'\n",
      " 'storage facility' 'pipeline facility' 'defence site']\n"
     ]
    }
   ],
   "source": [
    "vicmaps_categories = {\"eating\" : [], \n",
    "                  'groceries' : [], \n",
    "                  'shopping' : [], \n",
    "                  'errands' : ['hospital', 'health facility', 'place of worship'], \n",
    "                  'parks' : ['recreational resource', 'reserve','sport facility'], \n",
    "                  'education' : ['education centre'], \n",
    "                  'entertainment' : ['cultural centre', 'commercial facility', 'community venue'], \n",
    "                 'trains' : [], \n",
    "                 'transport' : []}\n",
    "\n",
    "\n",
    "vicmaps_categorised = categorise_pois(vicmaps, vicmaps_categories, \n",
    "                                  category_column='FTYPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f1bf6",
   "metadata": {},
   "source": [
    "Need to remove potential overlap between different data sources (and inside some data sources). For this dataset it's around 30% because there is overlap of public transport stops between OSM and transport agencies, and overlap of places like parks and schools between OSM and VicMaps. Then take this combined POI set and clip it to the study area: should be the same area as is covered by the network. This is important otherwise points outside the network may be erroneously linked to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "747397b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 35.67% duplicate points from dataframes\n"
     ]
    }
   ],
   "source": [
    "pois = remove_duplicate_pois([osm_categorised, vicmaps_categorised,\n",
    "                              metro_categorised], buffer=10)\n",
    "\n",
    "pois = gpd.clip(pois, Greater_Melbourne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ca191",
   "metadata": {},
   "source": [
    "Choose walk index weightings, and output the sums of each category and the total to check. The walk index will be out of 100 regardless of this sum, but it is important to note that eg. shopping is only '10% of the walk index' if shopping is 10 out of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd0dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_weights = {\n",
    "    \"employment\": [10],\n",
    "    \"eating\": [3, 3, 3, 2, 2, 1, 1, 1, 1, 1],\n",
    "    \"groceries\": [10, 4],\n",
    "    \"shopping\": [2, 2, 2, 2, 2],\n",
    "    \"errands\": [6, 2, 4],\n",
    "    \"parks\": [6],\n",
    "    \"education\": [10],\n",
    "    \"entertainment\": [5],\n",
    "    \"trains\": [10],\n",
    "    \"transport\": [2.5, 2.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2440fb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'employment': 10, 'eating': 18, 'groceries': 14, 'shopping': 10, 'errands': 12, 'parks': 6, 'education': 10, 'entertainment': 5, 'trains': 10, 'transport': 5.0}\n",
      "total:  100.0\n"
     ]
    }
   ],
   "source": [
    "category_sums = {k: sum(v) for k, v in poi_weights.items()}\n",
    "total = sum(category_sums.values())\n",
    "print(category_sums)\n",
    "print(\"total: \", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd7581",
   "metadata": {},
   "source": [
    "### Import network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b6f48",
   "metadata": {},
   "source": [
    "In this case the network is already in the same projected CRS as everything else but I have left in the transformation to be clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d529acc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z3258367\\Anaconda3\\envs\\ox\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3331: DtypeWarning: Columns (3,4,7,8,9,10,11,16,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\z3258367\\Anaconda3\\envs\\ox\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3331: DtypeWarning: Columns (6,13,14,16,17,18,19,21,22,28,29,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# reading directly with geopandas.read_file crashes on my computer so I read into pandas then convert to gdf instead\n",
    "edges_df = pd.read_csv(\"melbourne_edges_1.csv\")\n",
    "nodes_df = pd.read_csv(\"melbourne_nodes_1.csv\")\n",
    "edges = gpd.GeoDataFrame(edges_df, \n",
    "                         geometry=gpd.GeoSeries.from_wkt(edges_df['geometry'])).set_crs(proj_crs)\n",
    "nodes = gpd.GeoDataFrame(nodes_df, \n",
    "                         geometry=gpd.GeoSeries.from_wkt(nodes_df['geometry'])).set_crs(proj_crs)\n",
    "edges = edges.to_crs(proj_crs)\n",
    "nodes = nodes.to_crs(proj_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72395d9f",
   "metadata": {},
   "source": [
    "Pandana expects edges to have a two item index based on the same IDs as the node index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31dda610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes.set_index('connect_id',inplace=True)   #this is already the case this time for some reason\n",
    "\n",
    "edges['from_idx'] = edges['from']\n",
    "edges['to_idx'] = edges['to']\n",
    "edges= edges.set_index(['from_idx', 'to_idx'])\n",
    "edges.index.names= ['from_idx','to_idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea582800",
   "metadata": {},
   "source": [
    "Pandana network creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1149fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_network = pdna.Network(nodes['x'], nodes['y'],\n",
    "                                   edges['from'], edges['to'], \n",
    "                                   edges[['length']])\n",
    "\n",
    "maximum_dist = 2400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4efc6",
   "metadata": {},
   "source": [
    "Pandana network querying. The 'employment' category is empty because we didn't add the employment points to the POI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63e13f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category employment is empty\n",
      "Finished category: eating\n",
      "Finished category: groceries\n",
      "Finished category: shopping\n",
      "Finished category: errands\n",
      "Finished category: parks\n",
      "Finished category: education\n",
      "Finished category: entertainment\n",
      "Finished category: trains\n",
      "Finished category: transport\n"
     ]
    }
   ],
   "source": [
    "results = walk_index(distance_network, pois, poi_weights, distance=maximum_dist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9623a7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "connect_id\n",
       "0           250.427002\n",
       "1           233.880005\n",
       "2           173.108994\n",
       "3           124.064003\n",
       "4           132.106995\n",
       "              ...     \n",
       "4966796    1333.043945\n",
       "4966797    2400.000000\n",
       "4966798       2.363000\n",
       "4966799       8.776000\n",
       "4966800      26.636000\n",
       "Name: parks1, Length: 4637699, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['parks1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25ca93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"Melbourne_colournoemployment_220222.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc063b9",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8af95",
   "metadata": {},
   "source": [
    "The current approach is to find up to 100 closest employment nodes within the maximum distance. Then look up the number of jobs at each one, apply a distance decay function to each distance, multiply these together, and sum.\n",
    "\n",
    "An alternative approach which would be more convenient would be to use the Pandana 'aggregate' function which aggregates from all nodes within the maximum distance. However, there is limited ability to change the distance decay rate within the aggregation function. It can either be flat (no decay), linear (going to 0 at the max distance), or exponential where beta is set as 1/max distance. For walking I would like a beta of 0.001, but this requires the radius to be 1000m. If the radius is 2400m, beta is only 0.0004. This can be changed in the future if the Pandana function is updated to take a decay parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "438bb0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (employment_centrs['geometry'].x, employment_centrs['geometry'].y)\n",
    "\n",
    "distance_network.set_pois(category='employment', maxdist=maximum_dist, maxitems=100, x_col=x, y_col=y)\n",
    "\n",
    "employment_access = distance_network.nearest_pois(\n",
    "    distance=maximum_dist, category='employment', num_pois=100, include_poi_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c501b",
   "metadata": {},
   "source": [
    "The nearest_pois function returns both distances and the IDs of the nearest pois (with include_poi_ids option). The IDs can then be used to retrieve the number of jobs at each point. I found a merge was the fastest way to join this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c196467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itermerge(dataframe, jobs):\n",
    "    i=0\n",
    "    for column in dataframe:\n",
    "        dataframe = dataframe.merge(jobs, how='left', left_on = column, right_index = True, suffixes = [None, i])\n",
    "        i = i + 1\n",
    "    return dataframe\n",
    "\n",
    "def access_weight(x):\n",
    "        beta = -0.001\n",
    "        if x == maximum_dist:\n",
    "            return 0\n",
    "        else:\n",
    "            return math.exp(beta*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02b8a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobcounts = itermerge(employment_access.iloc[:,100:200], employment_centrs['MB Job Count'])\n",
    "\n",
    "results['jobs'] = ((employment_access.iloc[:,0:100].applymap(access_weight))*\n",
    "                                jobcounts.iloc[:,100:200].values\n",
    "                                ).sum(axis=1)\n",
    "\n",
    "weight = 100*sum(poi_weights['employment'])/sum(sum(list(poi_weights.values()),[]))\n",
    "\n",
    "results['employment'] = weight*results['jobs']/max(results['jobs'])\n",
    "\n",
    "results['Walk_Index'] = results['Walk_Index'] + results['employment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d110b0",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dfcd47",
   "metadata": {},
   "source": [
    "Filter the results to the original Colouring Sydney buildings only. Optionally export results as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ec2e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_results = results.filter(items=nodes[nodes['connect_type'] == 'poi'].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be4569d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_results.to_csv(\"Colouring_bf_results_180221.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb824b",
   "metadata": {},
   "source": [
    "Import building footprints and join the data to them, then export these polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f943788",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gdf = gpd.GeoDataFrame(building_results, geometry = gpd.GeoSeries.from_xy(building_results.x, building_results.y, crs=\"EPSG:7856\"))\n",
    "\n",
    "buildings_foot = gpd.read_file(folder + \"adelaide_bf.shp\").to_crs(proj_crs)\n",
    "\n",
    "# join to data\n",
    "buildings_foot = gpd.sjoin(buildings_foot, results_gdf, how='left', predicate='contains')\n",
    "\n",
    "buildings_foot.to_file(\"Colouring_bf_results_180221.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bf109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
